#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–åçš„å•ç»†èƒè½¬å½•ç»„æ•°æ®å¤„ç†æ¨¡å—
é‡‡ç”¨æœ€ä½³å®è·µï¼šç»Ÿä¸€è½¬æ¢ä¸ºH5ADæ ¼å¼ï¼Œç„¶åè¿›è¡Œå¤„ç†
æ”¯æŒCSV/TSV -> H5AD -> åˆ†æçš„å®Œæ•´æµç¨‹
"""

import sys
import os
import json
import traceback
import pandas as pd
import numpy as np
import scanpy as sc
import warnings
from pathlib import Path
from typing import Optional, Any, Union, Dict
from scipy.sparse import issparse

# å¯¼å…¥è½¬æ¢å™¨
try:
    # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
    import sys
    from pathlib import Path

    project_root = str(Path(__file__).parent.parent)
    if project_root not in sys.path:
        sys.path.insert(0, project_root)

    from analysis_scripts.matrix_to_h5ad_converter import MatrixToH5adConverter

    CONVERTER_AVAILABLE = True
except ImportError as e:
    CONVERTER_AVAILABLE = False
    print(f"è­¦å‘Š: matrix_to_h5ad_converter æ¨¡å—ä¸å¯ç”¨: {e}", file=sys.stderr)

# æŠ‘åˆ¶è­¦å‘Š
warnings.filterwarnings("ignore")
sc.settings.verbosity = 0  # æœ€å°åŒ–è¾“å‡º


class OptimizedSingleCellProcessor:
    """ä¼˜åŒ–çš„å•ç»†èƒæ•°æ®å¤„ç†å™¨ï¼Œé‡‡ç”¨æœ€ä½³å®è·µæµç¨‹"""

    def __init__(self):
        self.adata: Optional[sc.AnnData] = None

    def convert_to_h5ad_and_process(
        self,
        expression_file,
        metadata_file,
        reduction_method,
        color_by,
        save_h5ad="false",
        custom_filename="",
    ):
        """
        æœ€ä½³å®è·µæµç¨‹ï¼šç›´æ¥åœ¨å†…å­˜ä¸­è½¬æ¢å¹¶å¤„ç†ï¼Œé¿å…ä¸­é—´æ–‡ä»¶ã€‚
        è¿™ç¡®ä¿äº†æ•°æ®çš„å®Œæ•´æ€§å’Œclusterä¿¡æ¯çš„æ­£ç¡®å¯¹é½ã€‚
        """
        try:
            print(
                "=== å¼€å§‹å†…å­˜å¤„ç†æµç¨‹ï¼šCSV/TSV -> AnnData -> åˆ†æ ===", file=sys.stderr
            )

            if not CONVERTER_AVAILABLE:
                raise ImportError("è½¬æ¢å™¨æ¨¡å—ä¸å¯ç”¨ï¼Œæ— æ³•æ‰§è¡Œæ­¤æµç¨‹")

            # Step 1: åœ¨å†…å­˜ä¸­åˆ›å»ºå®Œæ•´çš„AnnDataå¯¹è±¡
            print("Step 1: åŠ è½½å¹¶è½¬æ¢æ•°æ®åˆ°å†…å­˜ä¸­çš„AnnDataå¯¹è±¡...", file=sys.stderr)
            converter = MatrixToH5adConverter()

            # æ£€æµ‹æ–‡ä»¶æ ¼å¼
            expr_format = "tsv" if expression_file.endswith((".tsv", ".txt")) else "csv"

            # åŠ è½½æ•°æ®
            print(f"æ­£åœ¨åŠ è½½è¡¨è¾¾çŸ©é˜µ: {expression_file}", file=sys.stderr)
            print(f"æ­£åœ¨åŠ è½½å…ƒæ•°æ®æ–‡ä»¶: {metadata_file}", file=sys.stderr)
            matrix_df, meta_df = converter.load_matrix_data(
                expression_file, metadata_file if metadata_file else None, expr_format
            )
            if matrix_df is None:
                raise ValueError("æ— æ³•åŠ è½½è¡¨è¾¾çŸ©é˜µ")

            # è¯¦ç»†æ£€æŸ¥åŠ è½½ç»“æœ
            print(
                f"è¡¨è¾¾çŸ©é˜µåŠ è½½ç»“æœ: {matrix_df.shape if matrix_df is not None else 'None'}",
                file=sys.stderr,
            )
            print(
                f"å…ƒæ•°æ®åŠ è½½ç»“æœ: {meta_df.shape if meta_df is not None else 'None'}",
                file=sys.stderr,
            )
            if meta_df is not None:
                print(f"å…ƒæ•°æ®åˆ—å: {list(meta_df.columns)}", file=sys.stderr)
                print(f"å…ƒæ•°æ®ç´¢å¼•å‰5ä¸ª: {list(meta_df.index[:5])}", file=sys.stderr)
            else:
                print("âš ï¸ è­¦å‘Šï¼šå…ƒæ•°æ®æ–‡ä»¶æœªèƒ½æˆåŠŸåŠ è½½ï¼", file=sys.stderr)

            # åˆ›å»ºAnnDataå¯¹è±¡
            adata = converter.create_anndata(matrix_df, meta_df)
            if adata is None:
                raise ValueError("æ— æ³•åˆ›å»ºAnnDataå¯¹è±¡")

            print("å†…å­˜ä¸­çš„AnnDataå¯¹è±¡åˆ›å»ºæˆåŠŸã€‚", file=sys.stderr)
            print(
                f"æ•°æ®ç»´åº¦: {adata.shape[0]} ç»†èƒ x {adata.shape[1]} åŸºå› ",
                file=sys.stderr,
            )
            print(f"æœ€ç»ˆçš„è§‚æµ‹æ•°æ®åˆ—: {list(adata.obs.columns)}", file=sys.stderr)

            # æ ¹æ®save_h5adå‚æ•°å†³å®šæ˜¯å¦ä¿å­˜H5ADæ–‡ä»¶
            h5ad_filename = None
            if save_h5ad.lower() == "true":
                import os
                from datetime import datetime

                output_dir = "./sample_data/output"
                os.makedirs(output_dir, exist_ok=True)

                # ç”Ÿæˆæ–‡ä»¶å
                if custom_filename:
                    # æ¸…ç†è‡ªå®šä¹‰æ–‡ä»¶åï¼Œç§»é™¤å¯èƒ½çš„.h5adåç¼€ï¼Œç¡®ä¿åªæœ‰ä¸€ä¸ª.h5adåç¼€
                    clean_filename = custom_filename.replace(".h5ad", "")
                    h5ad_filename = f"{clean_filename}.h5ad"
                else:
                    # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    h5ad_filename = f"converted_{timestamp}.h5ad"

                h5ad_path = os.path.join(output_dir, h5ad_filename)

                print(f"æ­£åœ¨ä¿å­˜H5ADæ–‡ä»¶åˆ°: {h5ad_path}", file=sys.stderr)
                adata.write_h5ad(h5ad_path)
                print(f"H5ADæ–‡ä»¶ä¿å­˜æˆåŠŸ: {h5ad_filename}", file=sys.stderr)
            else:
                print("è·³è¿‡H5ADæ–‡ä»¶ä¿å­˜ï¼ˆä»…åœ¨å†…å­˜ä¸­å¤„ç†ï¼‰", file=sys.stderr)

            # Step 2: ç›´æ¥å¤„ç†å†…å­˜ä¸­çš„AnnDataå¯¹è±¡
            result = self.process_h5ad(adata, reduction_method, color_by)

            # åœ¨ç»“æœä¸­æ·»åŠ H5ADæ–‡ä»¶åä¿¡æ¯ï¼ˆå¦‚æœä¿å­˜äº†æ–‡ä»¶ï¼‰
            if result and result.get("success") and h5ad_filename:
                # result å·²ç»æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œç›´æ¥æ·»åŠ  h5ad_filename
                result["h5ad_filename"] = h5ad_filename

                # é‡æ–°è¾“å‡ºä¿®æ”¹åçš„JSONæ•°æ®
                print("=== PLOT_DATA_START ===")
                print(json.dumps(result, ensure_ascii=False))
                print("=== PLOT_DATA_END ===")

                return result

            return result

        except Exception as e:
            error_msg = f"è½¬æ¢å’Œå¤„ç†æµç¨‹å¤±è´¥: {str(e)}"
            print(error_msg, file=sys.stderr)
            traceback.print_exc(file=sys.stderr)
            return self._output_error(error_msg)

    def process_h5ad(self, h5ad_input, reduction_method, color_by):
        """
        å¤„ç†H5ADæ–‡ä»¶æˆ–å†…å­˜ä¸­çš„AnnDataå¯¹è±¡ - ç»Ÿä¸€çš„å¤„ç†å…¥å£
        """
        try:
            if isinstance(h5ad_input, sc.AnnData):
                print("Step 2: å¤„ç†å†…å­˜ä¸­çš„AnnDataå¯¹è±¡...", file=sys.stderr)
                self.adata = h5ad_input
            else:
                print(
                    f"Step 2: ä»è·¯å¾„åŠ è½½å¹¶å¤„ç†H5ADæ–‡ä»¶: {h5ad_input}", file=sys.stderr
                )
                self.adata = sc.read_h5ad(h5ad_input)

            # æ£€æŸ¥adataæ˜¯å¦æˆåŠŸåŠ è½½
            if self.adata is None:
                raise ValueError("æ— æ³•åŠ è½½AnnDataå¯¹è±¡")

            print(
                f"åŠ è½½æ•°æ®: {self.adata.shape[0]} ç»†èƒ x {self.adata.shape[1]} åŸºå› ",
                file=sys.stderr,
            )

            # å¿«é€Ÿé¢„å¤„ç†
            self._quick_preprocess()

            # é™ç»´
            self._perform_dimensionality_reduction(reduction_method)

            # ç”Ÿæˆå¯è§†åŒ–æ•°æ®
            return self._generate_plot_data(reduction_method, color_by)

        except Exception as e:
            error_msg = f"H5ADå¤„ç†å¤±è´¥: {str(e)}"
            print(error_msg, file=sys.stderr)
            traceback.print_exc(file=sys.stderr)
            return self._output_error(error_msg)

    def _quick_preprocess(self):
        """å¿«é€Ÿé¢„å¤„ç†æµç¨‹"""
        # æ£€æŸ¥adataæ˜¯å¦å·²åŠ è½½
        if self.adata is None:
            raise ValueError("AnnDataå¯¹è±¡æœªåˆå§‹åŒ–")

        print("æ‰§è¡Œå¿«é€Ÿé¢„å¤„ç†...", file=sys.stderr)

        # åŸºæœ¬è¿‡æ»¤
        sc.pp.filter_cells(self.adata, min_genes=50)
        sc.pp.filter_genes(self.adata, min_cells=1)

        # æ ‡å‡†åŒ–
        sc.pp.normalize_total(self.adata, target_sum=1e4)
        sc.pp.log1p(self.adata)

        # é€‰æ‹©é«˜å˜åŸºå› 
        n_top_genes = min(2000, self.adata.shape[1])
        if self.adata.shape[1] > n_top_genes:
            try:
                sc.pp.highly_variable_genes(self.adata, n_top_genes=n_top_genes)
                self.adata.raw = self.adata
                self.adata = self.adata[:, self.adata.var.highly_variable]
            except:
                # å¦‚æœé«˜å˜åŸºå› é€‰æ‹©å¤±è´¥ï¼Œä½¿ç”¨æ–¹å·®é€‰æ‹©
                try:
                    # å¤„ç†ç¨€ç–çŸ©é˜µ
                    X_data = self.adata.X
                    # æ£€æŸ¥æ˜¯å¦ä¸ºç¨€ç–çŸ©é˜µå¹¶è½¬æ¢
                    if issparse(X_data):
                        # ç¨€ç–çŸ©é˜µè½¬æ¢ä¸ºå¯†é›†çŸ©é˜µ
                        gene_var = np.var(X_data.toarray(), axis=0)
                    else:
                        # å·²ç»æ˜¯å¯†é›†çŸ©é˜µæˆ–å…¶ä»–ç±»å‹
                        gene_var = np.var(X_data, axis=0)

                    # å¤„ç†å¯èƒ½çš„çŸ©é˜µåŒ…è£…ç±»å‹
                    if hasattr(gene_var, "A1"):
                        gene_var = gene_var.A1
                    top_genes_idx = np.argsort(gene_var)[-n_top_genes:]
                    self.adata = self.adata[:, top_genes_idx]
                except Exception as e:
                    print(f"é«˜å˜åŸºå› é€‰æ‹©å¤±è´¥: {e}", file=sys.stderr)
                    # ç»§ç»­ä½¿ç”¨æ‰€æœ‰åŸºå› 

        print(
            f"é¢„å¤„ç†åç»´åº¦: {self.adata.shape[0]} ç»†èƒ x {self.adata.shape[1]} åŸºå› ",
            file=sys.stderr,
        )

    def _perform_dimensionality_reduction(self, method):
        """æ‰§è¡Œé™ç»´"""
        # æ£€æŸ¥adataæ˜¯å¦å·²åŠ è½½
        if self.adata is None:
            raise ValueError("AnnDataå¯¹è±¡æœªåˆå§‹åŒ–")

        print(f"æ‰§è¡Œ{method.upper()}é™ç»´...", file=sys.stderr)

        # PCA
        sc.tl.pca(self.adata, svd_solver="arpack")

        # è®¡ç®—é‚»åŸŸå›¾
        sc.pp.neighbors(self.adata, n_neighbors=10, n_pcs=40)

        # æ‰§è¡ŒæŒ‡å®šçš„é™ç»´æ–¹æ³•
        if method.lower() == "tsne":
            sc.tl.tsne(self.adata)
        else:  # é»˜è®¤UMAP
            sc.tl.umap(self.adata)

    def _generate_plot_data(self, method, color_by):
        """ç”Ÿæˆç»˜å›¾æ•°æ®"""
        # æ£€æŸ¥adataæ˜¯å¦å·²åŠ è½½
        if self.adata is None:
            raise ValueError("AnnDataå¯¹è±¡æœªåˆå§‹åŒ–")

        try:
            # è·å–åæ ‡
            coord_key = f"X_{method.lower()}"
            if coord_key not in self.adata.obsm:
                coord_key = "X_umap"  # å¤‡ç”¨

            coordinates = self.adata.obsm[coord_key]
            x_coords = coordinates[:, 0].tolist()
            y_coords = coordinates[:, 1].tolist()

            # æ‰“å°å¯ç”¨çš„åˆ—ä¿¡æ¯ï¼Œå¸®åŠ©è°ƒè¯•
            print(f"å¯ç”¨çš„è§‚æµ‹æ•°æ®åˆ—: {list(self.adata.obs.columns)}", file=sys.stderr)
            print(f"è¯·æ±‚çš„ç€è‰²åˆ—: {color_by}", file=sys.stderr)

            # å¤„ç†é¢œè‰²æ•°æ® - å¢å¼ºé€»è¾‘
            color_data = None
            color_type = "default"
            used_color_column = None

            # æ¸…ç†color_byå‚æ•°ï¼šå¦‚æœæ˜¯ç©ºå­—ç¬¦ä¸²ï¼Œè®¾ä¸ºNone
            if color_by == "" or color_by == '""':
                color_by = None
                print(f"æ¸…ç†ç©ºå­—ç¬¦ä¸²ï¼Œè®¾ç½®color_byä¸ºNone", file=sys.stderr)

            # å¦‚æœæ²¡æœ‰æŒ‡å®šcolor_byæˆ–è€…æŒ‡å®šçš„åˆ—ä¸å­˜åœ¨ï¼Œå°è¯•è‡ªåŠ¨é€‰æ‹©
            if not color_by or color_by not in self.adata.obs.columns:
                # è‡ªåŠ¨å¯»æ‰¾æœ€ä½³çš„ç€è‰²åˆ—
                priority_columns = [
                    "cluster",
                    "clusters",
                    "louvain",
                    "leiden",
                    "cell_type",
                    "celltype",
                    "cell_types",
                    "seurat_clusters",
                    "RNA_snn_res",
                ]

                print(f"å¯»æ‰¾ç€è‰²åˆ—ï¼Œå½“å‰color_by: {color_by}", file=sys.stderr)
                for col in priority_columns:
                    if col in self.adata.obs.columns:
                        color_by = col
                        print(f"è‡ªåŠ¨é€‰æ‹©ç€è‰²åˆ—: {color_by}", file=sys.stderr)
                        break
                else:
                    print(f"æœªæ‰¾åˆ°ä¼˜å…ˆç€è‰²åˆ—ï¼Œå°†ä½¿ç”¨ç¬¬ä¸€ä¸ªåˆ†ç±»åˆ—", file=sys.stderr)

                # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªåˆ†ç±»åˆ—
                if not color_by or color_by not in self.adata.obs.columns:
                    categorical_columns = [
                        col
                        for col in self.adata.obs.columns
                        if self.adata.obs[col].dtype == "object"
                        or self.adata.obs[col].dtype.name == "category"
                    ]
                    if categorical_columns:
                        color_by = categorical_columns[0]
                        print(f"ä½¿ç”¨ç¬¬ä¸€ä¸ªåˆ†ç±»åˆ—ä½œä¸ºç€è‰²: {color_by}", file=sys.stderr)
                        print(f"å¯ç”¨çš„åˆ†ç±»åˆ—: {categorical_columns}", file=sys.stderr)

            if color_by and color_by in self.adata.obs.columns:
                color_values = self.adata.obs[color_by]

                # æ£€æŸ¥æ•°æ®ç±»å‹å’Œå†…å®¹
                print(
                    f"ç€è‰²åˆ— '{color_by}' çš„æ•°æ®ç±»å‹: {color_values.dtype}",
                    file=sys.stderr,
                )
                print(f"å”¯ä¸€å€¼ç¤ºä¾‹: {color_values.unique()[:10]}", file=sys.stderr)
                print(
                    f"éç©ºå€¼æ•°é‡: {color_values.notna().sum()}/{len(color_values)}",
                    file=sys.stderr,
                )

                if (
                    color_values.dtype == "object"
                    or color_values.dtype.name == "category"
                ):
                    # åˆ†ç±»æ•°æ®
                    color_type = "categorical"
                    # å¤„ç†åˆ†ç±»æ•°æ®ï¼Œåˆ›å»ºæ•°å€¼æ˜ å°„
                    unique_values = color_values.dropna().unique()
                    if len(unique_values) > 0:
                        value_to_index = {val: i for i, val in enumerate(unique_values)}
                        # ä¸ºç¼ºå¤±å€¼é¢„ç•™æœ€åä¸€ä¸ªç´¢å¼•
                        unknown_index = len(unique_values)
                        color_data = [
                            (
                                value_to_index.get(val, unknown_index)
                                if pd.notna(val)
                                else unknown_index
                            )
                            for val in color_values
                        ]
                        # æ·»åŠ ç±»åˆ«ä¿¡æ¯
                        categories = unique_values.tolist()
                        if unknown_index in color_data:  # æœ‰ç¼ºå¤±å€¼
                            categories.append("æœªçŸ¥")
                            print(
                                f"å‘ç° {color_data.count(unknown_index)} ä¸ªæœªçŸ¥ç±»å‹çš„ç»†èƒ",
                                file=sys.stderr,
                            )
                    else:
                        color_data = [0] * len(x_coords)
                        categories = ["é»˜è®¤"]
                else:
                    # æ•°å€¼æ•°æ®
                    color_type = "continuous"
                    color_data = color_values.fillna(0).tolist()
                    categories = None

                used_color_column = color_by
                print(f"ä½¿ç”¨{color_by}è¿›è¡Œç€è‰² (ç±»å‹: {color_type})", file=sys.stderr)
            else:
                # é»˜è®¤é¢œè‰² - åˆ›å»ºç®€å•çš„åŸºäºä½ç½®çš„åˆ†ç»„
                print("æ— æœ‰æ•ˆç€è‰²åˆ—ï¼Œåˆ›å»ºé»˜è®¤åˆ†ç»„", file=sys.stderr)
                n_groups = min(
                    8, max(2, len(x_coords) // 500)
                )  # æ ¹æ®ç»†èƒæ•°é‡å†³å®šåˆ†ç»„æ•°
                x_array = np.array(x_coords)
                # æ ¹æ®Xåæ ‡åˆ†ç»„
                bins = np.linspace(x_array.min(), x_array.max(), n_groups + 1)
                color_data = np.digitize(x_array, bins) - 1
                color_data = np.clip(color_data, 0, n_groups - 1).tolist()
                color_type = "categorical"
                categories = [f"ç»„{i+1}" for i in range(n_groups)]
                used_color_column = "ä½ç½®åˆ†ç»„"

            # æ„å»ºè¾“å‡ºæ•°æ®
            plot_data = {
                "x": x_coords,
                "y": y_coords,
                "color": color_data,  # ä¿æŒå…¼å®¹æ€§
                "color_values": color_data,  # å‰ç«¯æœŸæœ›çš„å­—æ®µå
                "color_type": color_type,
                "method": method.upper(),
                "n_cells": len(x_coords),
                "available_columns": list(self.adata.obs.columns),
                "used_color_column": used_color_column,
                "success": True,
            }

            # å¦‚æœæ˜¯åˆ†ç±»æ•°æ®ï¼Œæ·»åŠ ç±»åˆ«ä¿¡æ¯
            if color_type == "categorical" and categories is not None:
                plot_data["categories"] = categories
                category_display = (
                    categories[:10]
                    if len(categories) <= 10
                    else categories[:10] + ["..."]
                )
                print(
                    f"åˆ†ç±»ä¿¡æ¯: {category_display}",
                    file=sys.stderr,
                )

            print(
                f"æˆåŠŸç”Ÿæˆ{len(x_coords)}ä¸ªç»†èƒçš„{method.upper()}åæ ‡", file=sys.stderr
            )
            print(
                f"é¢œè‰²æ•°æ®èŒƒå›´: {min(color_data) if color_data else 'N/A'} - {max(color_data) if color_data else 'N/A'}",
                file=sys.stderr,
            )

            # è¾“å‡ºJSONæ•°æ®
            print("=== PLOT_DATA_START ===")
            print(json.dumps(plot_data, ensure_ascii=False))
            print("=== PLOT_DATA_END ===")

            return plot_data

        except Exception as e:
            error_msg = f"ç”Ÿæˆç»˜å›¾æ•°æ®å¤±è´¥: {str(e)}"
            print(error_msg, file=sys.stderr)
            traceback.print_exc(file=sys.stderr)
            return self._output_error(error_msg)

    def _output_error(self, error_message):
        """è¾“å‡ºé”™è¯¯ä¿¡æ¯"""
        error_data = {
            "error": error_message,
            "success": False,
            "x": [],
            "y": [],
            "color": [],
            "color_type": "error",
        }

        print("=== PLOT_DATA_START ===")
        print(json.dumps(error_data, ensure_ascii=False))
        print("=== PLOT_DATA_END ===")

        return error_data

    def get_data_summary(self, file_path: str) -> Dict[str, Any]:
        """
        è·å–H5ADæ•°æ®æ–‡ä»¶çš„è¯¦ç»†æ‘˜è¦ä¿¡æ¯

        Args:
            file_path (str): H5ADæ–‡ä»¶è·¯å¾„

        Returns:
            Dict[str, Any]: åŒ…å«æ•°æ®æ‘˜è¦çš„å­—å…¸
        """
        try:
            print(f"ğŸ“Š å¼€å§‹åˆ†ææ•°æ®æ‘˜è¦: {file_path}", file=sys.stderr)

            # è¯»å–H5ADæ–‡ä»¶
            import scanpy as sc
            adata = sc.read_h5ad(file_path)

            # åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
            n_cells = adata.shape[0]
            n_genes = adata.shape[1]

            # æ£€æŸ¥å¯ç”¨çš„è§‚æµ‹æ•°æ®åˆ—
            obs_columns = list(adata.obs.columns)
            var_columns = list(adata.var.columns)

            # æ£€æŸ¥å¯ç”¨çš„é™ç»´ç»“æœ
            available_embeddings = []
            if 'X_pca' in adata.obsm:
                available_embeddings.append('PCA')
            if 'X_umap' in adata.obsm:
                available_embeddings.append('UMAP')
            if 'X_tsne' in adata.obsm:
                available_embeddings.append('t-SNE')

            # æ£€æŸ¥èšç±»ä¿¡æ¯
            clustering_columns = []
            for col in obs_columns:
                if any(keyword in col.lower() for keyword in ['cluster', 'leiden', 'louvain']):
                    clustering_columns.append(col)

            # è®¡ç®—æ•°æ®è´¨é‡æŒ‡æ ‡
            quality_metrics = {}
            try:
                # è®¡ç®—æ¯ä¸ªç»†èƒçš„åŸºå› æ•°å’Œæ€»UMIæ•°
                if 'n_genes' in adata.obs:
                    quality_metrics['avg_genes_per_cell'] = float(adata.obs['n_genes'].mean())
                if 'total_counts' in adata.obs:
                    quality_metrics['avg_umi_per_cell'] = float(adata.obs['total_counts'].mean())

                # è®¡ç®—ç¨€ç–åº¦
                if hasattr(adata.X, 'nnz'):
                    # ç¨€ç–çŸ©é˜µ
                    sparsity = 1 - (adata.X.nnz / (adata.shape[0] * adata.shape[1]))
                else:
                    # å¯†é›†çŸ©é˜µ
                    sparsity = 1 - (np.count_nonzero(adata.X) / (adata.shape[0] * adata.shape[1]))
                quality_metrics['sparsity'] = float(sparsity)

            except Exception as e:
                print(f"è®¡ç®—è´¨é‡æŒ‡æ ‡æ—¶å‡ºé”™: {e}", file=sys.stderr)

            # æ–‡ä»¶ä¿¡æ¯
            file_info = {
                'file_path': file_path,
                'file_size_mb': round(Path(file_path).stat().st_size / (1024 * 1024), 2)
            }

            summary = {
                "success": True,
                "basic_info": {
                    "n_cells": n_cells,
                    "n_genes": n_genes,
                    "file_info": file_info
                },
                "data_structure": {
                    "obs_columns": obs_columns,
                    "var_columns": var_columns,
                    "available_embeddings": available_embeddings,
                    "clustering_columns": clustering_columns
                },
                "quality_metrics": quality_metrics,
                "analysis_suggestions": []
            }

            # æ·»åŠ åˆ†æå»ºè®®
            suggestions = []
            if not available_embeddings:
                suggestions.append("å»ºè®®å…ˆè¿›è¡Œé™ç»´åˆ†æ (UMAP, t-SNE, æˆ– PCA)")
            if not clustering_columns:
                suggestions.append("å»ºè®®è¿›è¡Œç»†èƒèšç±»åˆ†æ")
            if n_cells > 10000:
                suggestions.append("æ•°æ®é›†è¾ƒå¤§ï¼Œæ¨èä½¿ç”¨UMAPè¿›è¡Œå¿«é€Ÿå¯è§†åŒ–")
            elif n_cells < 1000:
                suggestions.append("æ•°æ®é›†è¾ƒå°ï¼Œå¯ä»¥å°è¯•æ›´ç²¾ç»†çš„åˆ†æå‚æ•°")

            summary["analysis_suggestions"] = suggestions

            print(f"âœ… æ•°æ®æ‘˜è¦åˆ†æå®Œæˆ: {n_cells}ç»†èƒ, {n_genes}åŸºå› ", file=sys.stderr)
            return summary

        except Exception as e:
            error_msg = f"æ•°æ®æ‘˜è¦åˆ†æå¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}", file=sys.stderr)
            traceback.print_exc(file=sys.stderr)

            return {
                "success": False,
                "error": error_msg,
                "details": str(e)
            }


def main():
    """ä¸»å‡½æ•° - ç®€åŒ–çš„å‘½ä»¤è¡Œæ¥å£"""

    if len(sys.argv) < 4:
        print(
            "ç”¨æ³•: python single_cell_processor.py <command> <file1> [file2] <method> [color_by]",
            file=sys.stderr,
        )
        print("å‘½ä»¤:", file=sys.stderr)
        print("  convert_to_h5ad_and_process: è½¬æ¢CSV/TSVä¸ºH5ADå¹¶å¤„ç†", file=sys.stderr)
        print("  process_h5ad: ç›´æ¥å¤„ç†H5ADæ–‡ä»¶", file=sys.stderr)
        sys.exit(1)

    processor = OptimizedSingleCellProcessor()

    command = sys.argv[1]

    try:
        if command == "convert_to_h5ad_and_process":
            # æœ€ä½³å®è·µæµç¨‹
            expression_file = sys.argv[2]
            metadata_file = sys.argv[3] if len(sys.argv) > 3 and sys.argv[3] else None
            reduction_method = sys.argv[4] if len(sys.argv) > 4 else "umap"
            color_by = sys.argv[5] if len(sys.argv) > 5 and sys.argv[5] else None
            save_h5ad = sys.argv[6] if len(sys.argv) > 6 else "false"
            custom_filename = sys.argv[7] if len(sys.argv) > 7 and sys.argv[7] else ""

            processor.convert_to_h5ad_and_process(
                expression_file,
                metadata_file,
                reduction_method,
                color_by,
                save_h5ad,
                custom_filename,
            )

        elif command == "process_h5ad":
            # ç›´æ¥å¤„ç†H5AD
            h5ad_file = sys.argv[2]
            reduction_method = sys.argv[3] if len(sys.argv) > 3 else "umap"
            color_by = sys.argv[4] if len(sys.argv) > 4 and sys.argv[4] else None

            processor.process_h5ad(h5ad_file, reduction_method, color_by)

        else:
            raise ValueError(f"æœªçŸ¥å‘½ä»¤: {command}")

    except Exception as e:
        processor._output_error(f"æ‰§è¡Œå¤±è´¥: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main()
