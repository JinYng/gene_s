#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
LangChain å·¥å…·å°è£…æ¨¡å—
å°†å•ç»†èƒžæ•°æ®åˆ†æžåŠŸèƒ½å°è£…ä¸ºLangChainå·¥å…·ï¼Œä¾›Agentæ™ºèƒ½è°ƒç”¨
"""

import sys
import json
import traceback
from pathlib import Path
from typing import Optional, Dict, Any, Union
from langchain.tools import tool

# å¯¼å…¥å•ç»†èƒžå¤„ç†å™¨
from .single_cell_processor import OptimizedSingleCellProcessor


@tool
def umap_analysis(file_path: str, color_by: str = "cluster") -> str:
    """
    å¯¹å•ç»†èƒžæ•°æ®æ‰§è¡ŒUMAPé™ç»´åˆ†æžå’Œå¯è§†åŒ–

    è¿™ä¸ªå·¥å…·å¯ä»¥ï¼š
    1. åŠ è½½H5ADæ ¼å¼çš„å•ç»†èƒžæ•°æ®æ–‡ä»¶
    2. æ‰§è¡ŒUMAPé™ç»´åˆ†æž
    3. æ ¹æ®æŒ‡å®šçš„é¢œè‰²ç¼–ç æ–¹å¼è¿›è¡Œå¯è§†åŒ–
    4. è¿”å›žå¯è§†åŒ–æ•°æ®ç”¨äºŽå‰ç«¯å±•ç¤º

    Args:
        file_path (str): H5ADæ•°æ®æ–‡ä»¶çš„å®Œæ•´è·¯å¾„
        color_by (str): ç”¨äºŽç€è‰²çš„å˜é‡åï¼Œé»˜è®¤ä¸º"cluster"
                       å¸¸ç”¨é€‰é¡¹åŒ…æ‹¬: "cluster", "cell_type", "leiden", "louvain"

    Returns:
        str: JSONæ ¼å¼çš„åˆ†æžç»“æžœï¼ŒåŒ…å«UMAPåæ ‡å’Œå¯è§†åŒ–æ•°æ®

    ç¤ºä¾‹ç”¨æ³•:
        - "å¯¹è¿™ä¸ªæ•°æ®è¿›è¡ŒUMAPé™ç»´åˆ†æž"
        - "åšä¸ªUMAPå›¾ï¼ŒæŒ‰clusterç€è‰²"
        - "ç”¨UMAPå¯è§†åŒ–è¿™äº›ç»†èƒž"
    """
    try:
        print(f"ðŸ§¬ å¼€å§‹UMAPåˆ†æž: {file_path}", file=sys.stderr)

        # åˆ›å»ºå¤„ç†å™¨å®žä¾‹
        processor = OptimizedSingleCellProcessor()

        # æ‰§è¡ŒUMAPåˆ†æž
        result = processor.process_h5ad(
            h5ad_input=file_path, reduction_method="umap", color_by=color_by
        )

        print(f"âœ… UMAPåˆ†æžå®Œæˆ", file=sys.stderr)

        # è¿”å›žJSONå­—ç¬¦ä¸²
        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        error_msg = f"UMAPåˆ†æžå¤±è´¥: {str(e)}"
        print(f"âŒ {error_msg}", file=sys.stderr)
        traceback.print_exc(file=sys.stderr)

        return json.dumps(
            {"success": False, "error": error_msg, "details": str(e)},
            ensure_ascii=False,
        )


@tool
def tsne_analysis(file_path: str, color_by: str = "cluster") -> str:
    """
    å¯¹å•ç»†èƒžæ•°æ®æ‰§è¡Œt-SNEé™ç»´åˆ†æžå’Œå¯è§†åŒ–

    è¿™ä¸ªå·¥å…·å¯ä»¥ï¼š
    1. åŠ è½½H5ADæ ¼å¼çš„å•ç»†èƒžæ•°æ®æ–‡ä»¶
    2. æ‰§è¡Œt-SNEé™ç»´åˆ†æž
    3. æ ¹æ®æŒ‡å®šçš„é¢œè‰²ç¼–ç æ–¹å¼è¿›è¡Œå¯è§†åŒ–
    4. è¿”å›žå¯è§†åŒ–æ•°æ®ç”¨äºŽå‰ç«¯å±•ç¤º

    Args:
        file_path (str): H5ADæ•°æ®æ–‡ä»¶çš„å®Œæ•´è·¯å¾„
        color_by (str): ç”¨äºŽç€è‰²çš„å˜é‡åï¼Œé»˜è®¤ä¸º"cluster"

    Returns:
        str: JSONæ ¼å¼çš„åˆ†æžç»“æžœï¼ŒåŒ…å«t-SNEåæ ‡å’Œå¯è§†åŒ–æ•°æ®

    ç¤ºä¾‹ç”¨æ³•:
        - "ç”¨t-SNEåˆ†æžè¿™ä¸ªæ•°æ®"
        - "åšä¸ªtsneå›¾"
        - "t-SNEé™ç»´å¯è§†åŒ–"
    """
    try:
        print(f"ðŸ§¬ å¼€å§‹t-SNEåˆ†æž: {file_path}", file=sys.stderr)

        # åˆ›å»ºå¤„ç†å™¨å®žä¾‹
        processor = OptimizedSingleCellProcessor()

        # æ‰§è¡Œt-SNEåˆ†æž
        result = processor.process_h5ad(
            h5ad_input=file_path, reduction_method="tsne", color_by=color_by
        )

        print(f"âœ… t-SNEåˆ†æžå®Œæˆ", file=sys.stderr)

        # è¿”å›žJSONå­—ç¬¦ä¸²
        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        error_msg = f"t-SNEåˆ†æžå¤±è´¥: {str(e)}"
        print(f"âŒ {error_msg}", file=sys.stderr)
        traceback.print_exc(file=sys.stderr)

        return json.dumps(
            {"success": False, "error": error_msg, "details": str(e)},
            ensure_ascii=False,
        )


@tool
def summarize_h5ad_data(file_path: str) -> str:
    """
    èŽ·å–H5ADå•ç»†èƒžæ•°æ®æ–‡ä»¶çš„è¯¦ç»†æ‘˜è¦ä¿¡æ¯

    è¿™ä¸ªå·¥å…·å¯ä»¥ï¼š
    1. è¯»å–H5ADæ•°æ®æ–‡ä»¶
    2. æå–åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯ï¼ˆç»†èƒžæ•°ã€åŸºå› æ•°ç­‰ï¼‰
    3. åˆ†æžæ•°æ®è´¨é‡æŒ‡æ ‡
    4. æ£€æŸ¥å¯ç”¨çš„å…ƒæ•°æ®åˆ—
    5. è¿”å›žæ˜“äºŽç†è§£çš„æ•°æ®æ‘˜è¦

    Args:
        file_path (str): H5ADæ•°æ®æ–‡ä»¶çš„å®Œæ•´è·¯å¾„

    Returns:
        str: JSONæ ¼å¼çš„æ•°æ®æ‘˜è¦ï¼ŒåŒ…å«æ‰€æœ‰å…³é”®ç»Ÿè®¡ä¿¡æ¯

    ç¤ºä¾‹ç”¨æ³•:
        - "è¿™ä¸ªæ–‡ä»¶é‡Œæœ‰å¤šå°‘ç»†èƒžï¼Ÿ"
        - "åˆ†æžä¸€ä¸‹æ•°æ®çš„åŸºæœ¬ä¿¡æ¯"
        - "æ•°æ®æ‘˜è¦"
        - "å‘Šè¯‰æˆ‘è¿™ä¸ªæ•°æ®é›†çš„åŸºæœ¬æƒ…å†µ"
    """
    try:
        print(f"ðŸ“Š å¼€å§‹æ•°æ®æ‘˜è¦åˆ†æž: {file_path}", file=sys.stderr)

        # åˆ›å»ºå¤„ç†å™¨å®žä¾‹
        processor = OptimizedSingleCellProcessor()

        # èŽ·å–æ•°æ®æ‘˜è¦
        summary = processor.get_data_summary(file_path)

        print(f"âœ… æ•°æ®æ‘˜è¦åˆ†æžå®Œæˆ", file=sys.stderr)

        # è¿”å›žJSONå­—ç¬¦ä¸²
        return json.dumps(summary, ensure_ascii=False, indent=2)

    except Exception as e:
        error_msg = f"æ•°æ®æ‘˜è¦åˆ†æžå¤±è´¥: {str(e)}"
        print(f"âŒ {error_msg}", file=sys.stderr)
        traceback.print_exc(file=sys.stderr)

        return json.dumps(
            {"success": False, "error": error_msg, "details": str(e)},
            ensure_ascii=False,
        )


@tool
def pca_analysis(file_path: str, color_by: str = "cluster") -> str:
    """
    å¯¹å•ç»†èƒžæ•°æ®æ‰§è¡ŒPCAä¸»æˆåˆ†åˆ†æžå’Œå¯è§†åŒ–

    è¿™ä¸ªå·¥å…·å¯ä»¥ï¼š
    1. åŠ è½½H5ADæ ¼å¼çš„å•ç»†èƒžæ•°æ®æ–‡ä»¶
    2. æ‰§è¡ŒPCAä¸»æˆåˆ†åˆ†æž
    3. æ ¹æ®æŒ‡å®šçš„é¢œè‰²ç¼–ç æ–¹å¼è¿›è¡Œå¯è§†åŒ–
    4. è¿”å›žå¯è§†åŒ–æ•°æ®ç”¨äºŽå‰ç«¯å±•ç¤º

    Args:
        file_path (str): H5ADæ•°æ®æ–‡ä»¶çš„å®Œæ•´è·¯å¾„
        color_by (str): ç”¨äºŽç€è‰²çš„å˜é‡åï¼Œé»˜è®¤ä¸º"cluster"

    Returns:
        str: JSONæ ¼å¼çš„åˆ†æžç»“æžœï¼ŒåŒ…å«PCAåæ ‡å’Œå¯è§†åŒ–æ•°æ®

    ç¤ºä¾‹ç”¨æ³•:
        - "ç”¨PCAåˆ†æžè¿™ä¸ªæ•°æ®"
        - "åšä¸ªä¸»æˆåˆ†åˆ†æž"
        - "PCAé™ç»´å¯è§†åŒ–"
    """
    try:
        print(f"ðŸ§¬ å¼€å§‹PCAåˆ†æž: {file_path}", file=sys.stderr)

        # åˆ›å»ºå¤„ç†å™¨å®žä¾‹
        processor = OptimizedSingleCellProcessor()

        # æ‰§è¡ŒPCAåˆ†æž
        result = processor.process_h5ad(
            h5ad_input=file_path, reduction_method="pca", color_by=color_by
        )

        print(f"âœ… PCAåˆ†æžå®Œæˆ", file=sys.stderr)

        # è¿”å›žJSONå­—ç¬¦ä¸²
        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        error_msg = f"PCAåˆ†æžå¤±è´¥: {str(e)}"
        print(f"âŒ {error_msg}", file=sys.stderr)
        traceback.print_exc(file=sys.stderr)

        return json.dumps(
            {"success": False, "error": error_msg, "details": str(e)},
            ensure_ascii=False,
        )


# å¯¼å‡ºæ‰€æœ‰å¯ç”¨å·¥å…·
available_tools = [umap_analysis, tsne_analysis, summarize_h5ad_data, pca_analysis]

# å·¥å…·åç§°åˆ°å‡½æ•°çš„æ˜ å°„ï¼ˆæ–¹ä¾¿è°ƒè¯•ï¼‰
tool_registry = {
    "umap_analysis": umap_analysis,
    "tsne_analysis": tsne_analysis,
    "summarize_h5ad_data": summarize_h5ad_data,
    "pca_analysis": pca_analysis,
}

if __name__ == "__main__":
    """
    æµ‹è¯•å·¥å…·åŠŸèƒ½
    """
    print("ðŸ§ª LangChain å·¥å…·æµ‹è¯•", file=sys.stderr)
    print(f"å¯ç”¨å·¥å…·æ•°é‡: {len(available_tools)}", file=sys.stderr)

    for tool in available_tools:
        print(f"  - {tool.name}: {tool.description.split('.')[0]}...", file=sys.stderr)

    # å¦‚æžœæä¾›äº†æµ‹è¯•æ–‡ä»¶è·¯å¾„ï¼Œè¿›è¡Œç®€å•æµ‹è¯•
    if len(sys.argv) > 1:
        test_file = sys.argv[1]
        print(f"\nðŸ§ª æµ‹è¯•æ–‡ä»¶: {test_file}", file=sys.stderr)

        # æµ‹è¯•æ•°æ®æ‘˜è¦
        print("\nðŸ“Š æµ‹è¯•æ•°æ®æ‘˜è¦:", file=sys.stderr)
        try:
            summary_result = summarize_h5ad_data.invoke({"file_path": test_file})
            result_preview = (
                summary_result[:200] + "..."
                if len(summary_result) > 200
                else summary_result
            )
            print(result_preview, file=sys.stderr)
        except Exception as e:
            print(f"æµ‹è¯•å¤±è´¥: {e}", file=sys.stderr)
