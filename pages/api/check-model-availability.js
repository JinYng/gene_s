// pages/api/check-model-availability.js
// AIæ¨¡å‹å¯ç”¨æ€§éªŒè¯API - ä½¿ç”¨LangChainç»Ÿä¸€å·¥å‚

import { ErrorHandler, createError } from "../../lib/errorHandler.js";
import { getConfig } from "../../config/index.js";
import { getModelById } from "../../config/models.js";
import { createChatModel } from "../../lib/llmFactory.js";
import { HumanMessage } from "@langchain/core/messages";

export default async function handler(req, res) {
  if (req.method !== "POST") {
    const error = createError.validation("method", "åªæ”¯æŒPOSTè¯·æ±‚");
    return res.status(405).json(ErrorHandler.formatErrorResponse(error));
  }

  try {
    const { modelId, apiKey, customConfig } = req.body;

    // éªŒè¯è¯·æ±‚å‚æ•°
    if (!modelId) {
      return res.status(400).json({
        success: false,
        status: "unavailable",
        message: "æ¨¡å‹IDä¸èƒ½ä¸ºç©º",
      });
    }

    // è·å–æ¨¡å‹é…ç½®
    const modelConfig = getModelById(modelId);
    if (!modelConfig) {
      return res.status(400).json({
        success: false,
        status: "unavailable",
        message: "æœªçŸ¥çš„æ¨¡å‹ID",
      });
    }

    console.log(`ğŸ” æ£€æŸ¥æ¨¡å‹å¯ç”¨æ€§: ${modelConfig.name} (${modelConfig.provider})`);

    // ä½¿ç”¨LangChainç»Ÿä¸€å·¥å‚è¿›è¡ŒéªŒè¯
    try {
      console.log(`ğŸ­ ä½¿ç”¨LangChainå·¥å‚åˆ›å»ºæ¨¡å‹: ${modelConfig.provider}`);

      let model;

      // å¦‚æœæ˜¯è‡ªå®šä¹‰æ¨¡å‹ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
      if (modelConfig.provider === 'Custom') {
        if (!customConfig || !customConfig.baseUrl || !customConfig.apiKey || !customConfig.model) {
          return res.status(400).json({
            success: false,
            status: "unconfigured",
            message: "è‡ªå®šä¹‰æ¨¡å‹é…ç½®ä¿¡æ¯ä¸å®Œæ•´",
            suggestion: "è¯·å¡«å†™å®Œæ•´çš„é…ç½®ä¿¡æ¯ï¼ˆåç§°ã€Base URLã€APIå¯†é’¥ã€æ¨¡å‹æ ‡è¯†ï¼‰",
          });
        }

        // æ„å»ºå®Œæ•´çš„modelPayloadå¯¹è±¡
        const modelPayload = {
          id: modelConfig.id,
          provider: modelConfig.provider,
          config: customConfig
        };

        console.log('ğŸ¤– éªŒè¯è‡ªå®šä¹‰æ¨¡å‹é…ç½®:', modelPayload);
        model = createChatModel(modelPayload);
      } else {
        // æ„å»ºé¢„å®šä¹‰æ¨¡å‹çš„modelPayloadå¯¹è±¡
        const modelPayload = {
          id: modelConfig.id,
          provider: modelConfig.provider,
          apiKey: apiKey,
          config: null
        };

        console.log('ğŸ¤– éªŒè¯é¢„å®šä¹‰æ¨¡å‹:', modelPayload);
        model = createChatModel(modelPayload);
      }

      // å‘é€ä¸€ä¸ªç®€çŸ­çš„æµ‹è¯•æ¶ˆæ¯æ¥éªŒè¯è¿æ¥
      console.log(`ğŸ§ª å‘é€æµ‹è¯•æ¶ˆæ¯éªŒè¯æ¨¡å‹...`);
      const testMessage = new HumanMessage("æµ‹è¯•");

      // è®¾ç½®è¾ƒçŸ­çš„è¶…æ—¶æ—¶é—´è¿›è¡Œå¿«é€ŸéªŒè¯
      await model.invoke([testMessage], { timeout: 10000 });

      console.log(`âœ… æ¨¡å‹ ${modelConfig.name} éªŒè¯æˆåŠŸ`);

      return res.status(200).json({
        success: true,
        status: "available",
        message: "æ¨¡å‹éªŒè¯æˆåŠŸ",
        provider: modelConfig.provider,
        modelName: modelConfig.name,
      });

    } catch (modelError) {
      console.error(`âŒ æ¨¡å‹éªŒè¯å¤±è´¥:`, modelError.message);

      // åŸºäºé”™è¯¯ç±»å‹æä¾›æ›´ç²¾ç¡®çš„é”™è¯¯ä¿¡æ¯
      let errorMessage = "æ¨¡å‹ä¸å¯ç”¨";
      let suggestion = "";
      let status = "unavailable";

      if (modelError.message.includes("API") || modelError.message.includes("å¯†é’¥")) {
        errorMessage = "APIå¯†é’¥éªŒè¯å¤±è´¥";
        suggestion = "è¯·æ£€æŸ¥æ‚¨çš„APIå¯†é’¥æ˜¯å¦æ­£ç¡®";
        status = "unconfigured";
      } else if (modelError.message.includes("timeout") || modelError.message.includes("è¶…æ—¶")) {
        errorMessage = "æœåŠ¡å“åº”è¶…æ—¶";
        suggestion = "è¯·ç¨åé‡è¯•";
      } else if (modelError.message.includes("Ollama") || modelError.message.includes("11434")) {
        errorMessage = "æœ¬åœ°OllamaæœåŠ¡ä¸å¯ç”¨";
        suggestion = "è¯·ç¡®ä¿OllamaæœåŠ¡æ­£åœ¨è¿è¡Œ (ollama serve)";
      } else if (modelError.message.includes("æ¨¡å‹") && modelError.message.includes("éœ€è¦")) {
        errorMessage = "APIå¯†é’¥ç¼ºå¤±";
        suggestion = "æ­¤æ¨¡å‹éœ€è¦APIå¯†é’¥æ‰èƒ½ä½¿ç”¨";
        status = "unconfigured";
      } else if (modelError.message.includes("ä¸æ”¯æŒçš„")) {
        errorMessage = "æ¨¡å‹æä¾›å•†ä¸æ”¯æŒ";
        suggestion = "è¯·é€‰æ‹©å…¶ä»–å¯ç”¨çš„æ¨¡å‹";
      }

      return res.status(200).json({
        success: false,
        status: status,
        message: errorMessage,
        suggestion: suggestion,
        provider: modelConfig.provider,
        modelName: modelConfig.name,
        originalError: modelError.message,
      });
    }

  } catch (error) {
    console.error("âŒ æ¨¡å‹å¯ç”¨æ€§æ£€æŸ¥å¤±è´¥:", error);

    const errorResponse = ErrorHandler.formatErrorResponse(error);
    return res.status(500).json({
      success: false,
      status: "unavailable",
      message: errorResponse.message || "æ£€æŸ¥æ¨¡å‹å¯ç”¨æ€§æ—¶å‘ç”Ÿé”™è¯¯",
    });
  }
}

// æ³¨æ„ï¼šæ‰€æœ‰åŸæ¥çš„æä¾›å•†ç‰¹å®šæ£€æŸ¥å‡½æ•°ï¼ˆcheckOllamaAvailability, checkZhipuAvailability, checkOpenAIAvailabilityï¼‰
// ç°åœ¨éƒ½è¢«LangChainç»Ÿä¸€å·¥å‚æ›¿ä»£äº†ï¼Œä¸å†éœ€è¦è¿™äº›å‡½æ•°